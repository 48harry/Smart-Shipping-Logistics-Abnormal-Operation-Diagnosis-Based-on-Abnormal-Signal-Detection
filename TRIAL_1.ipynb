{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Gwfh-RAZmgMZHjyg8NIAfWKEmv4y2lX5",
      "authorship_tag": "ABX9TyNc+mOBoHRnunowOtn0q1/y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/48harry/Smart-Shipping-Logistics-Abnormal-Operation-Diagnosis-Based-on-Abnormal-Signal-Detection/blob/main/TRIAL_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cn_M-3iFb26Y",
        "outputId": "5664d5a7-ef65-4b5b-d866-250377a36204"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load models...\n",
            " OK.\n",
            "Load test data...\n",
            " meta=10, Araw=4, Braw=6\n",
            " mapped: A=4, B=6\n",
            "Step 1: Age, TestDate 파생...\n",
            "Step 2: A1 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 14327.26it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 4279.90it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 4042.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 3: A2 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 16448.25it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 16085.54it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 7581.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 4: A3 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 16895.48it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 10908.46it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 7028.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 5: A4 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 6293.03it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 10356.31it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 10803.10it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 5835.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 6: A5 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 7175.88it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 6269.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 7: 시퀀스 컬럼 drop & concat...\n",
            "A 검사 데이터 전처리 완료\n",
            "Step 1: Age, TestDate 파생...\n",
            "Step 2: B1 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:00<00:00, 21272.89it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 13196.55it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 4192.91it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 14146.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 3: B2 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:00<00:00, 20295.02it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 6785.07it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 4812.74it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10690.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 4: B3 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:00<00:00, 22055.94it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 13834.98it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10200.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 5: B4 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:00<00:00, 21041.66it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 7527.92it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 8112.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 6: B5 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:00<00:00, 25784.66it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 13996.57it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10722.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 7: B6~B8 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:00<00:00, 28826.83it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 31030.61it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 31976.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 8: 시퀀스 컬럼 drop & concat...\n",
            "B 검사 데이터 전처리 완료\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " aligned: XA=(4, 62), XB=(6, 46)\n",
            "Inference Model...\n",
            "Saved: /content/drive/MyDrive/dacon_driver/submission_1.csv (rows=10)\n"
          ]
        }
      ],
      "source": [
        "#TRIAL 1\n",
        "\n",
        "import os, argparse, joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import lightgbm as lgb\n",
        "\n",
        "# =======================\n",
        "# 학습 때 사용한 전처리 유틸\n",
        "# =======================\n",
        "tqdm.pandas()\n",
        "\n",
        "def convert_age(val):\n",
        "    if pd.isna(val): return np.nan\n",
        "    try:\n",
        "        base = int(str(val)[:-1])\n",
        "        return base if str(val)[-1] == \"a\" else base + 5\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "def split_testdate(val):\n",
        "    try:\n",
        "        v = int(val)\n",
        "        return v // 100, v % 100\n",
        "    except:\n",
        "        return np.nan, np.nan\n",
        "\n",
        "def seq_mean(series):\n",
        "    return series.fillna(\"\").progress_apply(\n",
        "        lambda x: np.fromstring(x, sep=\",\").mean() if x else np.nan\n",
        "    )\n",
        "\n",
        "def seq_std(series):\n",
        "    return series.fillna(\"\").progress_apply(\n",
        "        lambda x: np.fromstring(x, sep=\",\").std() if x else np.nan\n",
        "    )\n",
        "\n",
        "def seq_rate(series, target=\"1\"):\n",
        "    return series.fillna(\"\").progress_apply(\n",
        "        lambda x: str(x).split(\",\").count(target) / len(x.split(\",\")) if x else np.nan\n",
        "    )\n",
        "\n",
        "def masked_mean_from_csv_series(cond_series, val_series, mask_val):\n",
        "    cond_df = cond_series.fillna(\"\").str.split(\",\", expand=True).replace(\"\", np.nan)\n",
        "    val_df  = val_series.fillna(\"\").str.split(\",\", expand=True).replace(\"\", np.nan)\n",
        "    cond_arr = cond_df.to_numpy(dtype=float)\n",
        "    val_arr  = val_df.to_numpy(dtype=float)\n",
        "    mask = (cond_arr == mask_val)\n",
        "    with np.errstate(invalid=\"ignore\"):\n",
        "        sums = np.nansum(np.where(mask, val_arr, np.nan), axis=1)\n",
        "        counts = np.sum(mask, axis=1)\n",
        "        out = sums / np.where(counts==0, np.nan, counts)\n",
        "    return pd.Series(out, index=cond_series.index)\n",
        "\n",
        "def masked_mean_in_set_series(cond_series, val_series, mask_set):\n",
        "    cond_df = cond_series.fillna(\"\").str.split(\",\", expand=True).replace(\"\", np.nan)\n",
        "    val_df  = val_series.fillna(\"\").str.split(\",\", expand=True).replace(\"\", np.nan)\n",
        "    cond_arr = cond_df.to_numpy(dtype=float)\n",
        "    val_arr  = val_df.to_numpy(dtype=float)\n",
        "    mask = np.isin(cond_arr, list(mask_set))\n",
        "    with np.errstate(invalid=\"ignore\"):\n",
        "        sums = np.nansum(np.where(mask, val_arr, np.nan), axis=1)\n",
        "        counts = np.sum(mask, axis=1)\n",
        "        out = sums / np.where(counts == 0, np.nan, counts)\n",
        "    return pd.Series(out, index=cond_series.index)\n",
        "\n",
        "# =======================\n",
        "# 학습 때 사용한 A/B 검사 전처리 (그대로)\n",
        "# =======================\n",
        "def preprocess_A(train_A):\n",
        "    df = train_A.copy()\n",
        "    print(\"Step 1: Age, TestDate 파생...\")\n",
        "    df[\"Age_num\"] = df[\"Age\"].map(convert_age)\n",
        "    ym = df[\"TestDate\"].map(split_testdate)\n",
        "    df[\"Year\"] = [y for y, m in ym]\n",
        "    df[\"Month\"] = [m for y, m in ym]\n",
        "\n",
        "    feats = pd.DataFrame(index=df.index)\n",
        "\n",
        "    print(\"Step 2: A1 feature 생성...\")\n",
        "    feats[\"A1_resp_rate\"] = seq_rate(df[\"A1-3\"], \"1\")\n",
        "    feats[\"A1_rt_mean\"]   = seq_mean(df[\"A1-4\"])\n",
        "    feats[\"A1_rt_std\"]    = seq_std(df[\"A1-4\"])\n",
        "    feats[\"A1_rt_left\"]   = masked_mean_from_csv_series(df[\"A1-1\"], df[\"A1-4\"], 1)\n",
        "    feats[\"A1_rt_right\"]  = masked_mean_from_csv_series(df[\"A1-1\"], df[\"A1-4\"], 2)\n",
        "    feats[\"A1_rt_side_diff\"] = feats[\"A1_rt_left\"] - feats[\"A1_rt_right\"]\n",
        "    feats[\"A1_rt_slow\"]   = masked_mean_from_csv_series(df[\"A1-2\"], df[\"A1-4\"], 1)\n",
        "    feats[\"A1_rt_fast\"]   = masked_mean_from_csv_series(df[\"A1-2\"], df[\"A1-4\"], 3)\n",
        "    feats[\"A1_rt_speed_diff\"] = feats[\"A1_rt_slow\"] - feats[\"A1_rt_fast\"]\n",
        "\n",
        "    print(\"Step 3: A2 feature 생성...\")\n",
        "    feats[\"A2_resp_rate\"] = seq_rate(df[\"A2-3\"], \"1\")\n",
        "    feats[\"A2_rt_mean\"]   = seq_mean(df[\"A2-4\"])\n",
        "    feats[\"A2_rt_std\"]    = seq_std(df[\"A2-4\"])\n",
        "    feats[\"A2_rt_cond1_diff\"] = masked_mean_from_csv_series(df[\"A2-1\"], df[\"A2-4\"], 1) - \\\n",
        "                                masked_mean_from_csv_series(df[\"A2-1\"], df[\"A2-4\"], 3)\n",
        "    feats[\"A2_rt_cond2_diff\"] = masked_mean_from_csv_series(df[\"A2-2\"], df[\"A2-4\"], 1) - \\\n",
        "                                masked_mean_from_csv_series(df[\"A2-2\"], df[\"A2-4\"], 3)\n",
        "\n",
        "    print(\"Step 4: A3 feature 생성...\")\n",
        "    s = df[\"A3-5\"].fillna(\"\")\n",
        "    total   = s.apply(lambda x: len(x.split(\",\")) if x else 0)\n",
        "    valid   = s.apply(lambda x: sum(v in {\"1\",\"2\"} for v in x.split(\",\")) if x else 0)\n",
        "    invalid = s.apply(lambda x: sum(v in {\"3\",\"4\"} for v in x.split(\",\")) if x else 0)\n",
        "    correct = s.apply(lambda x: sum(v in {\"1\",\"3\"} for v in x.split(\",\")) if x else 0)\n",
        "    feats[\"A3_valid_ratio\"]   = (valid / total).replace([np.inf,-np.inf], np.nan)\n",
        "    feats[\"A3_invalid_ratio\"] = (invalid / total).replace([np.inf,-np.inf], np.nan)\n",
        "    feats[\"A3_correct_ratio\"] = (correct / total).replace([np.inf,-np.inf], np.nan)\n",
        "\n",
        "    feats[\"A3_resp2_rate\"] = seq_rate(df[\"A3-6\"], \"1\")\n",
        "    feats[\"A3_rt_mean\"]    = seq_mean(df[\"A3-7\"])\n",
        "    feats[\"A3_rt_std\"]     = seq_std(df[\"A3-7\"])\n",
        "    feats[\"A3_rt_size_diff\"] = masked_mean_from_csv_series(df[\"A3-1\"], df[\"A3-7\"], 1) - \\\n",
        "                               masked_mean_from_csv_series(df[\"A3-1\"], df[\"A3-7\"], 2)\n",
        "    feats[\"A3_rt_side_diff\"] = masked_mean_from_csv_series(df[\"A3-3\"], df[\"A3-7\"], 1) - \\\n",
        "                               masked_mean_from_csv_series(df[\"A3-3\"], df[\"A3-7\"], 2)\n",
        "\n",
        "    print(\"Step 5: A4 feature 생성...\")\n",
        "    feats[\"A4_acc_rate\"]   = seq_rate(df[\"A4-3\"], \"1\")\n",
        "    feats[\"A4_resp2_rate\"] = seq_rate(df[\"A4-4\"], \"1\")\n",
        "    feats[\"A4_rt_mean\"]    = seq_mean(df[\"A4-5\"])\n",
        "    feats[\"A4_rt_std\"]     = seq_std(df[\"A4-5\"])\n",
        "    feats[\"A4_stroop_diff\"] = masked_mean_from_csv_series(df[\"A4-1\"], df[\"A4-5\"], 2) - \\\n",
        "                              masked_mean_from_csv_series(df[\"A4-1\"], df[\"A4-5\"], 1)\n",
        "    feats[\"A4_rt_color_diff\"] = masked_mean_from_csv_series(df[\"A4-2\"], df[\"A4-5\"], 1) - \\\n",
        "                                masked_mean_from_csv_series(df[\"A4-2\"], df[\"A4-5\"], 2)\n",
        "\n",
        "    print(\"Step 6: A5 feature 생성...\")\n",
        "    feats[\"A5_acc_rate\"]   = seq_rate(df[\"A5-2\"], \"1\")\n",
        "    feats[\"A5_resp2_rate\"] = seq_rate(df[\"A5-3\"], \"1\")\n",
        "    feats[\"A5_acc_nonchange\"] = masked_mean_from_csv_series(df[\"A5-1\"], df[\"A5-2\"], 1)\n",
        "    feats[\"A5_acc_change\"]    = masked_mean_in_set_series(df[\"A5-1\"], df[\"A5-2\"], {2,3,4})\n",
        "\n",
        "    print(\"Step 7: 시퀀스 컬럼 drop & concat...\")\n",
        "    seq_cols = [\n",
        "        \"A1-1\",\"A1-2\",\"A1-3\",\"A1-4\",\n",
        "        \"A2-1\",\"A2-2\",\"A2-3\",\"A2-4\",\n",
        "        \"A3-1\",\"A3-2\",\"A3-3\",\"A3-4\",\"A3-5\",\"A3-6\",\"A3-7\",\n",
        "        \"A4-1\",\"A4-2\",\"A4-3\",\"A4-4\",\"A4-5\",\n",
        "        \"A5-1\",\"A5-2\",\"A5-3\"\n",
        "    ]\n",
        "    print(\"A 검사 데이터 전처리 완료\")\n",
        "    out = pd.concat([df.drop(columns=seq_cols, errors=\"ignore\"), feats], axis=1)\n",
        "    out.replace([np.inf,-np.inf], np.nan, inplace=True)\n",
        "    return out\n",
        "\n",
        "def preprocess_B(train_B):\n",
        "    df = train_B.copy()\n",
        "    print(\"Step 1: Age, TestDate 파생...\")\n",
        "    df[\"Age_num\"] = df[\"Age\"].map(convert_age)\n",
        "    ym = df[\"TestDate\"].map(split_testdate)\n",
        "    df[\"Year\"] = [y for y, m in ym]\n",
        "    df[\"Month\"] = [m for y, m in ym]\n",
        "\n",
        "    feats = pd.DataFrame(index=df.index)\n",
        "\n",
        "    print(\"Step 2: B1 feature 생성...\")\n",
        "    feats[\"B1_acc_task1\"] = seq_rate(df[\"B1-1\"], \"1\")\n",
        "    feats[\"B1_rt_mean\"]   = seq_mean(df[\"B1-2\"])\n",
        "    feats[\"B1_rt_std\"]    = seq_std(df[\"B1-2\"])\n",
        "    feats[\"B1_acc_task2\"] = seq_rate(df[\"B1-3\"], \"1\")\n",
        "\n",
        "    print(\"Step 3: B2 feature 생성...\")\n",
        "    feats[\"B2_acc_task1\"] = seq_rate(df[\"B2-1\"], \"1\")\n",
        "    feats[\"B2_rt_mean\"]   = seq_mean(df[\"B2-2\"])\n",
        "    feats[\"B2_rt_std\"]    = seq_std(df[\"B2-2\"])\n",
        "    feats[\"B2_acc_task2\"] = seq_rate(df[\"B2-3\"], \"1\")\n",
        "\n",
        "    print(\"Step 4: B3 feature 생성...\")\n",
        "    feats[\"B3_acc_rate\"] = seq_rate(df[\"B3-1\"], \"1\")\n",
        "    feats[\"B3_rt_mean\"]  = seq_mean(df[\"B3-2\"])\n",
        "    feats[\"B3_rt_std\"]   = seq_std(df[\"B3-2\"])\n",
        "\n",
        "    print(\"Step 5: B4 feature 생성...\")\n",
        "    feats[\"B4_acc_rate\"] = seq_rate(df[\"B4-1\"], \"1\")\n",
        "    feats[\"B4_rt_mean\"]  = seq_mean(df[\"B4-2\"])\n",
        "    feats[\"B4_rt_std\"]   = seq_std(df[\"B4-2\"])\n",
        "\n",
        "    print(\"Step 6: B5 feature 생성...\")\n",
        "    feats[\"B5_acc_rate\"] = seq_rate(df[\"B5-1\"], \"1\")\n",
        "    feats[\"B5_rt_mean\"]  = seq_mean(df[\"B5-2\"])\n",
        "    feats[\"B5_rt_std\"]   = seq_std(df[\"B5-2\"])\n",
        "\n",
        "    print(\"Step 7: B6~B8 feature 생성...\")\n",
        "    feats[\"B6_acc_rate\"] = seq_rate(df[\"B6\"], \"1\")\n",
        "    feats[\"B7_acc_rate\"] = seq_rate(df[\"B7\"], \"1\")\n",
        "    feats[\"B8_acc_rate\"] = seq_rate(df[\"B8\"], \"1\")\n",
        "\n",
        "    print(\"Step 8: 시퀀스 컬럼 drop & concat...\")\n",
        "    seq_cols = [\n",
        "        \"B1-1\",\"B1-2\",\"B1-3\",\n",
        "        \"B2-1\",\"B2-2\",\"B2-3\",\n",
        "        \"B3-1\",\"B3-2\",\n",
        "        \"B4-1\",\"B4-2\",\n",
        "        \"B5-1\",\"B5-2\",\n",
        "        \"B6\",\"B7\",\"B8\"\n",
        "    ]\n",
        "    print(\"B 검사 데이터 전처리 완료\")\n",
        "    out = pd.concat([df.drop(columns=seq_cols, errors=\"ignore\"), feats], axis=1)\n",
        "    out.replace([np.inf,-np.inf], np.nan, inplace=True)\n",
        "    return out\n",
        "\n",
        "# =======================\n",
        "# 학습 때 사용한 파생 (그대로)\n",
        "# =======================\n",
        "def _has(df, cols):  return all(c in df.columns for c in cols)\n",
        "def _safe_div(a, b, eps=1e-6): return a / (b + eps)\n",
        "\n",
        "def add_features_A(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    feats = df.copy(); eps = 1e-6\n",
        "    if _has(feats, [\"Year\",\"Month\"]):\n",
        "        feats[\"YearMonthIndex\"] = feats[\"Year\"] * 12 + feats[\"Month\"]\n",
        "\n",
        "    if _has(feats, [\"A1_rt_mean\",\"A1_resp_rate\"]):\n",
        "        feats[\"A1_speed_acc_tradeoff\"] = _safe_div(feats[\"A1_rt_mean\"], feats[\"A1_resp_rate\"], eps)\n",
        "    if _has(feats, [\"A2_rt_mean\",\"A2_resp_rate\"]):\n",
        "        feats[\"A2_speed_acc_tradeoff\"] = _safe_div(feats[\"A2_rt_mean\"], feats[\"A2_resp_rate\"], eps)\n",
        "    if _has(feats, [\"A4_rt_mean\",\"A4_acc_rate\"]):\n",
        "        feats[\"A4_speed_acc_tradeoff\"] = _safe_div(feats[\"A4_rt_mean\"], feats[\"A4_acc_rate\"], eps)\n",
        "\n",
        "    for k in [\"A1\",\"A2\",\"A3\",\"A4\"]:\n",
        "        m, s = f\"{k}_rt_mean\", f\"{k}_rt_std\"\n",
        "        if _has(feats, [m, s]):\n",
        "            feats[f\"{k}_rt_cv\"] = _safe_div(feats[s], feats[m], eps)\n",
        "\n",
        "    for name, base in [\n",
        "        (\"A1_rt_side_gap_abs\",  \"A1_rt_side_diff\"),\n",
        "        (\"A1_rt_speed_gap_abs\", \"A1_rt_speed_diff\"),\n",
        "        (\"A2_rt_cond1_gap_abs\", \"A2_rt_cond1_diff\"),\n",
        "        (\"A2_rt_cond2_gap_abs\", \"A2_rt_cond2_diff\"),\n",
        "        (\"A4_stroop_gap_abs\",   \"A4_stroop_diff\"),\n",
        "        (\"A4_color_gap_abs\",    \"A4_rt_color_diff\"),\n",
        "    ]:\n",
        "        if base in feats.columns:\n",
        "            feats[name] = feats[base].abs()\n",
        "\n",
        "    if _has(feats, [\"A3_valid_ratio\",\"A3_invalid_ratio\"]):\n",
        "        feats[\"A3_valid_invalid_gap\"] = feats[\"A3_valid_ratio\"] - feats[\"A3_invalid_ratio\"]\n",
        "    if _has(feats, [\"A3_correct_ratio\",\"A3_invalid_ratio\"]):\n",
        "        feats[\"A3_correct_invalid_gap\"] = feats[\"A3_correct_ratio\"] - feats[\"A3_invalid_ratio\"]\n",
        "    if _has(feats, [\"A5_acc_change\",\"A5_acc_nonchange\"]):\n",
        "        feats[\"A5_change_nonchange_gap\"] = feats[\"A5_acc_change\"] - feats[\"A5_acc_nonchange\"]\n",
        "\n",
        "    feats.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    return feats\n",
        "\n",
        "def add_features_B(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    feats = df.copy(); eps = 1e-6\n",
        "    if _has(feats, [\"Year\",\"Month\"]):\n",
        "        feats[\"YearMonthIndex\"] = feats[\"Year\"] * 12 + feats[\"Month\"]\n",
        "\n",
        "    for k, acc_col, rt_col in [\n",
        "        (\"B1\", \"B1_acc_task1\", \"B1_rt_mean\"),\n",
        "        (\"B2\", \"B2_acc_task1\", \"B2_rt_mean\"),\n",
        "        (\"B3\", \"B3_acc_rate\",  \"B3_rt_mean\"),\n",
        "        (\"B4\", \"B4_acc_rate\",  \"B4_rt_mean\"),\n",
        "        (\"B5\", \"B5_acc_rate\",  \"B5_rt_mean\"),\n",
        "    ]:\n",
        "        if _has(feats, [rt_col, acc_col]):\n",
        "            feats[f\"{k}_speed_acc_tradeoff\"] = _safe_div(feats[rt_col], feats[acc_col], eps)\n",
        "\n",
        "    for k in [\"B1\",\"B2\",\"B3\",\"B4\",\"B5\"]:\n",
        "        m, s = f\"{k}_rt_mean\", f\"{k}_rt_std\"\n",
        "        if _has(feats, [m, s]):\n",
        "            feats[f\"{k}_rt_cv\"] = _safe_div(feats[s], feats[m], eps)\n",
        "\n",
        "    parts = []\n",
        "    for k in [\"B4\",\"B5\"]:\n",
        "        if _has(feats, [f\"{k}_rt_cv\"]):\n",
        "            parts.append(0.25 * feats[f\"{k}_rt_cv\"].fillna(0))\n",
        "    for k in [\"B3\",\"B4\",\"B5\"]:\n",
        "        acc = f\"{k}_acc_rate\" if k not in [\"B1\",\"B2\"] else None\n",
        "        if k in [\"B1\",\"B2\"]:\n",
        "            acc = f\"{k}_acc_task1\"\n",
        "        if acc in feats:\n",
        "            parts.append(0.25 * (1 - feats[acc].fillna(0)))\n",
        "    for k in [\"B1\",\"B2\"]:\n",
        "        tcol = f\"{k}_speed_acc_tradeoff\"\n",
        "        if tcol in feats:\n",
        "            parts.append(0.25 * feats[tcol].fillna(0))\n",
        "    if parts:\n",
        "        feats[\"RiskScore_B\"] = sum(parts)\n",
        "\n",
        "    feats.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    return feats\n",
        "\n",
        "# =======================\n",
        "# 정렬/보정 (모델이 학습 때 본 피처 순서로)\n",
        "# =======================\n",
        "DROP_COLS = [\"Test_id\",\"Test\",\"PrimaryKey\",\"Age\",\"TestDate\"]\n",
        "\n",
        "def align_to_model(X_df, model):\n",
        "    feat_names = list(getattr(model, \"feature_name_\", []))\n",
        "    if not feat_names:\n",
        "        # fallback: 그냥 숫자형만\n",
        "        X = X_df.select_dtypes(include=[np.number]).copy()\n",
        "        return X.fillna(0.0)\n",
        "    X = X_df.drop(columns=[c for c in DROP_COLS if c in X_df.columns], errors=\"ignore\").copy()\n",
        "    # 누락 피처 0으로 채움\n",
        "    for c in feat_names:\n",
        "        if c not in X.columns:\n",
        "            X[c] = 0.0\n",
        "    # 초과 피처 드롭 + 순서 일치\n",
        "    X = X[feat_names]\n",
        "    return X.apply(pd.to_numeric, errors=\"coerce\").fillna(0.0)\n",
        "\n",
        "# =======================\n",
        "# main\n",
        "# =======================\n",
        "def main():\n",
        "\n",
        "    trial = 1\n",
        "\n",
        "    # ---- 경로 변수 (필요에 따라 수정) ----\n",
        "    TEST_DIR  = \"/content/drive/MyDrive/dacon_driver/data\"              # test.csv, A.csv, B.csv, sample_submission.csv 위치\n",
        "    MODEL_DIR = \"/content/drive/MyDrive/dacon_driver/pkl\"             # lgbm_A.pkl, lgbm_B.pkl 위치\n",
        "    OUT_DIR   = \"/content/drive/MyDrive/dacon_driver\"\n",
        "    SAMPLE_SUB_PATH = os.path.join(TEST_DIR, \"sample_submission.csv\")\n",
        "    OUT_PATH  = os.path.join(OUT_DIR, f\"submission_{trial}.csv\")\n",
        "\n",
        "    # ---- 모델 로드 ----\n",
        "    print(\"Load models...\")\n",
        "    model_A = joblib.load(os.path.join(MODEL_DIR, f\"A_{trial}.pkl\"))\n",
        "    model_B = joblib.load(os.path.join(MODEL_DIR, f\"B_{trial}.pkl\"))\n",
        "    print(\" OK.\")\n",
        "\n",
        "    # ---- 테스트 데이터 로드 ----\n",
        "    print(\"Load test data...\")\n",
        "    meta = pd.read_csv(os.path.join(TEST_DIR, \"test.csv\"))\n",
        "    Araw = pd.read_csv(os.path.join(TEST_DIR, \"./test/A.csv\"))\n",
        "    Braw = pd.read_csv(os.path.join(TEST_DIR, \"./test/B.csv\"))\n",
        "    print(f\" meta={len(meta)}, Araw={len(Araw)}, Braw={len(Braw)}\")\n",
        "\n",
        "    # ---- 매핑 ----\n",
        "    A_df = meta.loc[meta[\"Test\"] == \"A\", [\"Test_id\", \"Test\"]].merge(Araw, on=\"Test_id\", how=\"left\")\n",
        "    B_df = meta.loc[meta[\"Test\"] == \"B\", [\"Test_id\", \"Test\"]].merge(Braw, on=\"Test_id\", how=\"left\")\n",
        "    print(f\" mapped: A={len(A_df)}, B={len(B_df)}\")\n",
        "\n",
        "    # ---- 전처리 → 파생 (학습과 동일) ----\n",
        "    A_feat = add_features_A(preprocess_A(A_df)) if len(A_df) else pd.DataFrame()\n",
        "    B_feat = add_features_B(preprocess_B(B_df)) if len(B_df) else pd.DataFrame()\n",
        "\n",
        "    # ---- 피처 정렬/보정 ----\n",
        "    XA = align_to_model(A_feat, model_A) if len(A_feat) else pd.DataFrame(columns=getattr(model_A,\"feature_name_\",[]))\n",
        "    XB = align_to_model(B_feat, model_B) if len(B_feat) else pd.DataFrame(columns=getattr(model_B,\"feature_name_\",[]))\n",
        "    print(f\" aligned: XA={XA.shape}, XB={XB.shape}\")\n",
        "\n",
        "    # ---- 예측 ----\n",
        "    print(\"Inference Model...\")\n",
        "    predA = model_A.predict_proba(XA)[:,1] if len(XA) else np.array([])\n",
        "    predB = model_B.predict_proba(XB)[:,1] if len(XB) else np.array([])\n",
        "\n",
        "    # ---- Test_id와 합치기 ----\n",
        "    subA = pd.DataFrame({\"Test_id\": A_df[\"Test_id\"].values, \"prob\": predA})\n",
        "    subB = pd.DataFrame({\"Test_id\": B_df[\"Test_id\"].values, \"prob\": predB})\n",
        "    probs = pd.concat([subA, subB], axis=0, ignore_index=True)\n",
        "\n",
        "    # ---- sample_submission 기반 결과 생성 (Label 컬럼에 0~1 확률 채움) ----\n",
        "    os.makedirs(OUT_DIR, exist_ok=True)\n",
        "    sample = pd.read_csv(SAMPLE_SUB_PATH)\n",
        "\n",
        "    # sample의 Test_id 순서에 맞추어 prob 병합\n",
        "    out = sample.merge(probs, on=\"Test_id\", how=\"left\")\n",
        "    out[\"Label\"] = out[\"prob\"].astype(float).fillna(0.0)\n",
        "    out = out.drop(columns=[\"prob\"])\n",
        "\n",
        "    out.to_csv(OUT_PATH, index=False)\n",
        "    print(f\"Saved: {OUT_PATH} (rows={len(out)})\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}